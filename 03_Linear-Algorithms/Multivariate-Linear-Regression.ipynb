{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9062571-4feb-4882-991f-161bf7e55a70",
   "metadata": {},
   "source": [
    "# Multivariate linear regression using stochastic gradient descent\n",
    "\n",
    "So we will be implementing a multivariate linear regresssion model using stochastic gradient descent.\n",
    "Gradient descent in ML is the process of minimizing a function following the slope or gradient of that function.\n",
    "\n",
    "### How does it work?\n",
    "The way this optimization algorithm works is that each training instance is shown to the\n",
    "model one at a time. The model makes a prediction for a training instance, the error is calculated\n",
    "and the model is updated in order to reduce the error for the next prediction. This process is\n",
    "repeated for a fixed number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc790a7-9f9c-459e-8803-5befc592fd71",
   "metadata": {},
   "source": [
    "# Steps in this tutorial\n",
    "\n",
    "1. Make predictions\n",
    "2. Estimate coefficients\n",
    "3. Case study on [Wine dataset](https://www.kaggle.com/datasets/rajyellow46/wine-quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf43bf-be34-4b75-b5e2-c2e1be9f4019",
   "metadata": {},
   "source": [
    "## Making predictions function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf2df6df-2c1f-4c51-a6e5-576d26c44399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(row, coefficients):\n",
    "    yhat = coefficients[0]\n",
    "    \n",
    "    for i in range(len(row) - 1):\n",
    "        yhat += coefficients[i+1] * row[i]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a3b08-3a67-4a47-85b2-d55f6b3c8c59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing this on a dummy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ae3c3b3-0b4d-4c99-a46b-35a1c4560acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1, Predicted: 1.2\n",
      "Expected: 3, Predicted: 2.0\n",
      "Expected: 3, Predicted: 3.6\n",
      "Expected: 2, Predicted: 2.8\n",
      "Expected: 5, Predicted: 4.4\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "coef = [0.4, 0.8]\n",
    "for row in dataset:\n",
    "    yhat = prediction(row, coef)\n",
    "    print(f\"Expected: {row[-1]}, Predicted: {round(yhat, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8a326-e341-4ce1-8ae9-7ebc16dfe1b5",
   "metadata": {},
   "source": [
    "## Estimating coefficients\n",
    "\n",
    "Two important terms to keep in mind:\n",
    "\n",
    "1. Learning rate\n",
    "Used to limit the amount that each coefficient is corrected each time it\n",
    "is updated.\n",
    "2. Epochs:\n",
    "The number of times to run through the training data while updating the\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ce5051-2759-433f-a9f8-e4fd55e36a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = prediction(row, coef)\n",
    "            error = yhat - row[-1]\n",
    "            sum_error += (error**2)\n",
    "            \n",
    "            coef[0] = coef[0] - l_rate * error\n",
    "            \n",
    "            for i in range (len(row) - 1):\n",
    "                coef[i+1] = coef[i+1] - l_rate * error * row[i]\n",
    "        print(f\"epoch: {epoch}; lrate: {round(l_rate, 3)}; error: {round(sum_error, 3)}\")\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f154287-656f-4c24-ac0a-5133163c76e3",
   "metadata": {},
   "source": [
    "## Testing on dummy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21ea72bd-6058-4b2a-bf34-6d407cae62e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0; lrate: 0.001; error: 46.236\n",
      "epoch: 1; lrate: 0.001; error: 41.305\n",
      "epoch: 2; lrate: 0.001; error: 36.93\n",
      "epoch: 3; lrate: 0.001; error: 33.047\n",
      "epoch: 4; lrate: 0.001; error: 29.601\n",
      "epoch: 5; lrate: 0.001; error: 26.543\n",
      "epoch: 6; lrate: 0.001; error: 23.83\n",
      "epoch: 7; lrate: 0.001; error: 21.422\n",
      "epoch: 8; lrate: 0.001; error: 19.285\n",
      "epoch: 9; lrate: 0.001; error: 17.389\n",
      "[0.10710331074898374, 0.3801081881174074]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "l_rate = 0.001\n",
    "epoch = 10\n",
    "\n",
    "coef = coefficients_sgd(dataset, l_rate, epoch)\n",
    "print(coef)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50bf3e-38e4-47d1-83bf-34528b7123c5",
   "metadata": {},
   "source": [
    "# Wine case study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a91168-862a-4fc8-9ed0-586735273c09",
   "metadata": {},
   "source": [
    "## Dataset preparation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c300ac97-5eb7-4d9c-8f99-31eb2aa972e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "# Load csv function\n",
    "def load_csv_skip(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, \"r\") as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "        return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "        \n",
    "# pop the first row \n",
    "def pop_first_row(dataset):\n",
    "    dataset.pop(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173902b2-e0ff-4a5c-8ebd-e1bec4c98e76",
   "metadata": {},
   "source": [
    "## Normalization, cross-validation split, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c710b5ac-a2fc-4105-9655-8f43cbaf29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax\n",
    "\n",
    "# Normalizing the data\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "\n",
    "# Calculate root mean squared error\n",
    "def rmse_metric(actual, predicted):\n",
    "\tsum_error = 0.0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tprediction_error = predicted[i] - actual[i]\n",
    "\t\tsum_error += (prediction_error ** 2)\n",
    "\tmean_error = sum_error / float(len(actual))\n",
    "\treturn sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc85aba-8a85-421d-b8a6-dc70c44db4e1",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d27118eb-36e8-4fd8-bc2d-601d42aecb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\trmse = rmse_metric(actual, predicted)\n",
    "\t\tscores.append(rmse)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379c050-0361-4fee-a2fb-cd8281ed74cc",
   "metadata": {},
   "source": [
    "## Linear regression with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "384092f4-fff1-4a04-a611-cc761f1dfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "\tfor row in test:\n",
    "\t\tyhat = prediction(row, coef)\n",
    "\t\tpredictions.append(yhat)\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ddf24b-41c0-470d-a1ed-d95f90b27144",
   "metadata": {},
   "source": [
    "## Multivariate linear regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60b85829-63ef-4204-8564-fb4005029210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0; lrate: 0.01; error: 95.749\n",
      "epoch: 1; lrate: 0.01; error: 81.046\n",
      "epoch: 2; lrate: 0.01; error: 79.556\n",
      "epoch: 3; lrate: 0.01; error: 78.795\n",
      "epoch: 4; lrate: 0.01; error: 78.318\n",
      "epoch: 5; lrate: 0.01; error: 78.004\n",
      "epoch: 6; lrate: 0.01; error: 77.793\n",
      "epoch: 7; lrate: 0.01; error: 77.647\n",
      "epoch: 8; lrate: 0.01; error: 77.545\n",
      "epoch: 9; lrate: 0.01; error: 77.472\n",
      "epoch: 10; lrate: 0.01; error: 77.418\n",
      "epoch: 11; lrate: 0.01; error: 77.378\n",
      "epoch: 12; lrate: 0.01; error: 77.348\n",
      "epoch: 13; lrate: 0.01; error: 77.324\n",
      "epoch: 14; lrate: 0.01; error: 77.305\n",
      "epoch: 15; lrate: 0.01; error: 77.29\n",
      "epoch: 16; lrate: 0.01; error: 77.277\n",
      "epoch: 17; lrate: 0.01; error: 77.266\n",
      "epoch: 18; lrate: 0.01; error: 77.257\n",
      "epoch: 19; lrate: 0.01; error: 77.249\n",
      "epoch: 20; lrate: 0.01; error: 77.242\n",
      "epoch: 21; lrate: 0.01; error: 77.235\n",
      "epoch: 22; lrate: 0.01; error: 77.23\n",
      "epoch: 23; lrate: 0.01; error: 77.224\n",
      "epoch: 24; lrate: 0.01; error: 77.22\n",
      "epoch: 25; lrate: 0.01; error: 77.215\n",
      "epoch: 26; lrate: 0.01; error: 77.211\n",
      "epoch: 27; lrate: 0.01; error: 77.207\n",
      "epoch: 28; lrate: 0.01; error: 77.204\n",
      "epoch: 29; lrate: 0.01; error: 77.2\n",
      "epoch: 30; lrate: 0.01; error: 77.197\n",
      "epoch: 31; lrate: 0.01; error: 77.193\n",
      "epoch: 32; lrate: 0.01; error: 77.19\n",
      "epoch: 33; lrate: 0.01; error: 77.187\n",
      "epoch: 34; lrate: 0.01; error: 77.185\n",
      "epoch: 35; lrate: 0.01; error: 77.182\n",
      "epoch: 36; lrate: 0.01; error: 77.179\n",
      "epoch: 37; lrate: 0.01; error: 77.177\n",
      "epoch: 38; lrate: 0.01; error: 77.174\n",
      "epoch: 39; lrate: 0.01; error: 77.171\n",
      "epoch: 40; lrate: 0.01; error: 77.169\n",
      "epoch: 41; lrate: 0.01; error: 77.167\n",
      "epoch: 42; lrate: 0.01; error: 77.164\n",
      "epoch: 43; lrate: 0.01; error: 77.162\n",
      "epoch: 44; lrate: 0.01; error: 77.16\n",
      "epoch: 45; lrate: 0.01; error: 77.158\n",
      "epoch: 46; lrate: 0.01; error: 77.155\n",
      "epoch: 47; lrate: 0.01; error: 77.153\n",
      "epoch: 48; lrate: 0.01; error: 77.151\n",
      "epoch: 49; lrate: 0.01; error: 77.149\n",
      "epoch: 0; lrate: 0.01; error: 97.332\n",
      "epoch: 1; lrate: 0.01; error: 82.613\n",
      "epoch: 2; lrate: 0.01; error: 80.96\n",
      "epoch: 3; lrate: 0.01; error: 80.124\n",
      "epoch: 4; lrate: 0.01; error: 79.603\n",
      "epoch: 5; lrate: 0.01; error: 79.258\n",
      "epoch: 6; lrate: 0.01; error: 79.023\n",
      "epoch: 7; lrate: 0.01; error: 78.857\n",
      "epoch: 8; lrate: 0.01; error: 78.738\n",
      "epoch: 9; lrate: 0.01; error: 78.65\n",
      "epoch: 10; lrate: 0.01; error: 78.584\n",
      "epoch: 11; lrate: 0.01; error: 78.533\n",
      "epoch: 12; lrate: 0.01; error: 78.493\n",
      "epoch: 13; lrate: 0.01; error: 78.461\n",
      "epoch: 14; lrate: 0.01; error: 78.435\n",
      "epoch: 15; lrate: 0.01; error: 78.413\n",
      "epoch: 16; lrate: 0.01; error: 78.395\n",
      "epoch: 17; lrate: 0.01; error: 78.379\n",
      "epoch: 18; lrate: 0.01; error: 78.366\n",
      "epoch: 19; lrate: 0.01; error: 78.354\n",
      "epoch: 20; lrate: 0.01; error: 78.344\n",
      "epoch: 21; lrate: 0.01; error: 78.335\n",
      "epoch: 22; lrate: 0.01; error: 78.326\n",
      "epoch: 23; lrate: 0.01; error: 78.319\n",
      "epoch: 24; lrate: 0.01; error: 78.312\n",
      "epoch: 25; lrate: 0.01; error: 78.306\n",
      "epoch: 26; lrate: 0.01; error: 78.301\n",
      "epoch: 27; lrate: 0.01; error: 78.295\n",
      "epoch: 28; lrate: 0.01; error: 78.291\n",
      "epoch: 29; lrate: 0.01; error: 78.286\n",
      "epoch: 30; lrate: 0.01; error: 78.282\n",
      "epoch: 31; lrate: 0.01; error: 78.278\n",
      "epoch: 32; lrate: 0.01; error: 78.274\n",
      "epoch: 33; lrate: 0.01; error: 78.271\n",
      "epoch: 34; lrate: 0.01; error: 78.267\n",
      "epoch: 35; lrate: 0.01; error: 78.264\n",
      "epoch: 36; lrate: 0.01; error: 78.261\n",
      "epoch: 37; lrate: 0.01; error: 78.258\n",
      "epoch: 38; lrate: 0.01; error: 78.255\n",
      "epoch: 39; lrate: 0.01; error: 78.252\n",
      "epoch: 40; lrate: 0.01; error: 78.25\n",
      "epoch: 41; lrate: 0.01; error: 78.247\n",
      "epoch: 42; lrate: 0.01; error: 78.244\n",
      "epoch: 43; lrate: 0.01; error: 78.242\n",
      "epoch: 44; lrate: 0.01; error: 78.24\n",
      "epoch: 45; lrate: 0.01; error: 78.237\n",
      "epoch: 46; lrate: 0.01; error: 78.235\n",
      "epoch: 47; lrate: 0.01; error: 78.233\n",
      "epoch: 48; lrate: 0.01; error: 78.23\n",
      "epoch: 49; lrate: 0.01; error: 78.228\n",
      "epoch: 0; lrate: 0.01; error: 97.469\n",
      "epoch: 1; lrate: 0.01; error: 83.414\n",
      "epoch: 2; lrate: 0.01; error: 82.019\n",
      "epoch: 3; lrate: 0.01; error: 81.317\n",
      "epoch: 4; lrate: 0.01; error: 80.878\n",
      "epoch: 5; lrate: 0.01; error: 80.589\n",
      "epoch: 6; lrate: 0.01; error: 80.394\n",
      "epoch: 7; lrate: 0.01; error: 80.259\n",
      "epoch: 8; lrate: 0.01; error: 80.163\n",
      "epoch: 9; lrate: 0.01; error: 80.094\n",
      "epoch: 10; lrate: 0.01; error: 80.043\n",
      "epoch: 11; lrate: 0.01; error: 80.004\n",
      "epoch: 12; lrate: 0.01; error: 79.974\n",
      "epoch: 13; lrate: 0.01; error: 79.951\n",
      "epoch: 14; lrate: 0.01; error: 79.932\n",
      "epoch: 15; lrate: 0.01; error: 79.916\n",
      "epoch: 16; lrate: 0.01; error: 79.903\n",
      "epoch: 17; lrate: 0.01; error: 79.892\n",
      "epoch: 18; lrate: 0.01; error: 79.883\n",
      "epoch: 19; lrate: 0.01; error: 79.874\n",
      "epoch: 20; lrate: 0.01; error: 79.867\n",
      "epoch: 21; lrate: 0.01; error: 79.86\n",
      "epoch: 22; lrate: 0.01; error: 79.854\n",
      "epoch: 23; lrate: 0.01; error: 79.849\n",
      "epoch: 24; lrate: 0.01; error: 79.844\n",
      "epoch: 25; lrate: 0.01; error: 79.839\n",
      "epoch: 26; lrate: 0.01; error: 79.835\n",
      "epoch: 27; lrate: 0.01; error: 79.831\n",
      "epoch: 28; lrate: 0.01; error: 79.827\n",
      "epoch: 29; lrate: 0.01; error: 79.823\n",
      "epoch: 30; lrate: 0.01; error: 79.82\n",
      "epoch: 31; lrate: 0.01; error: 79.816\n",
      "epoch: 32; lrate: 0.01; error: 79.813\n",
      "epoch: 33; lrate: 0.01; error: 79.81\n",
      "epoch: 34; lrate: 0.01; error: 79.807\n",
      "epoch: 35; lrate: 0.01; error: 79.804\n",
      "epoch: 36; lrate: 0.01; error: 79.801\n",
      "epoch: 37; lrate: 0.01; error: 79.798\n",
      "epoch: 38; lrate: 0.01; error: 79.796\n",
      "epoch: 39; lrate: 0.01; error: 79.793\n",
      "epoch: 40; lrate: 0.01; error: 79.791\n",
      "epoch: 41; lrate: 0.01; error: 79.788\n",
      "epoch: 42; lrate: 0.01; error: 79.786\n",
      "epoch: 43; lrate: 0.01; error: 79.783\n",
      "epoch: 44; lrate: 0.01; error: 79.781\n",
      "epoch: 45; lrate: 0.01; error: 79.779\n",
      "epoch: 46; lrate: 0.01; error: 79.776\n",
      "epoch: 47; lrate: 0.01; error: 79.774\n",
      "epoch: 48; lrate: 0.01; error: 79.772\n",
      "epoch: 49; lrate: 0.01; error: 79.77\n",
      "epoch: 0; lrate: 0.01; error: 96.742\n",
      "epoch: 1; lrate: 0.01; error: 82.502\n",
      "epoch: 2; lrate: 0.01; error: 80.904\n",
      "epoch: 3; lrate: 0.01; error: 80.102\n",
      "epoch: 4; lrate: 0.01; error: 79.606\n",
      "epoch: 5; lrate: 0.01; error: 79.282\n",
      "epoch: 6; lrate: 0.01; error: 79.063\n",
      "epoch: 7; lrate: 0.01; error: 78.912\n",
      "epoch: 8; lrate: 0.01; error: 78.806\n",
      "epoch: 9; lrate: 0.01; error: 78.729\n",
      "epoch: 10; lrate: 0.01; error: 78.672\n",
      "epoch: 11; lrate: 0.01; error: 78.629\n",
      "epoch: 12; lrate: 0.01; error: 78.596\n",
      "epoch: 13; lrate: 0.01; error: 78.57\n",
      "epoch: 14; lrate: 0.01; error: 78.549\n",
      "epoch: 15; lrate: 0.01; error: 78.532\n",
      "epoch: 16; lrate: 0.01; error: 78.518\n",
      "epoch: 17; lrate: 0.01; error: 78.506\n",
      "epoch: 18; lrate: 0.01; error: 78.495\n",
      "epoch: 19; lrate: 0.01; error: 78.486\n",
      "epoch: 20; lrate: 0.01; error: 78.478\n",
      "epoch: 21; lrate: 0.01; error: 78.47\n",
      "epoch: 22; lrate: 0.01; error: 78.463\n",
      "epoch: 23; lrate: 0.01; error: 78.457\n",
      "epoch: 24; lrate: 0.01; error: 78.451\n",
      "epoch: 25; lrate: 0.01; error: 78.446\n",
      "epoch: 26; lrate: 0.01; error: 78.441\n",
      "epoch: 27; lrate: 0.01; error: 78.436\n",
      "epoch: 28; lrate: 0.01; error: 78.431\n",
      "epoch: 29; lrate: 0.01; error: 78.427\n",
      "epoch: 30; lrate: 0.01; error: 78.422\n",
      "epoch: 31; lrate: 0.01; error: 78.418\n",
      "epoch: 32; lrate: 0.01; error: 78.414\n",
      "epoch: 33; lrate: 0.01; error: 78.411\n",
      "epoch: 34; lrate: 0.01; error: 78.407\n",
      "epoch: 35; lrate: 0.01; error: 78.403\n",
      "epoch: 36; lrate: 0.01; error: 78.4\n",
      "epoch: 37; lrate: 0.01; error: 78.396\n",
      "epoch: 38; lrate: 0.01; error: 78.393\n",
      "epoch: 39; lrate: 0.01; error: 78.389\n",
      "epoch: 40; lrate: 0.01; error: 78.386\n",
      "epoch: 41; lrate: 0.01; error: 78.383\n",
      "epoch: 42; lrate: 0.01; error: 78.38\n",
      "epoch: 43; lrate: 0.01; error: 78.377\n",
      "epoch: 44; lrate: 0.01; error: 78.374\n",
      "epoch: 45; lrate: 0.01; error: 78.371\n",
      "epoch: 46; lrate: 0.01; error: 78.368\n",
      "epoch: 47; lrate: 0.01; error: 78.365\n",
      "epoch: 48; lrate: 0.01; error: 78.362\n",
      "epoch: 49; lrate: 0.01; error: 78.359\n",
      "epoch: 0; lrate: 0.01; error: 95.365\n",
      "epoch: 1; lrate: 0.01; error: 81.336\n",
      "epoch: 2; lrate: 0.01; error: 79.901\n",
      "epoch: 3; lrate: 0.01; error: 79.18\n",
      "epoch: 4; lrate: 0.01; error: 78.724\n",
      "epoch: 5; lrate: 0.01; error: 78.422\n",
      "epoch: 6; lrate: 0.01; error: 78.215\n",
      "epoch: 7; lrate: 0.01; error: 78.07\n",
      "epoch: 8; lrate: 0.01; error: 77.966\n",
      "epoch: 9; lrate: 0.01; error: 77.89\n",
      "epoch: 10; lrate: 0.01; error: 77.833\n",
      "epoch: 11; lrate: 0.01; error: 77.79\n",
      "epoch: 12; lrate: 0.01; error: 77.756\n",
      "epoch: 13; lrate: 0.01; error: 77.729\n",
      "epoch: 14; lrate: 0.01; error: 77.708\n",
      "epoch: 15; lrate: 0.01; error: 77.69\n",
      "epoch: 16; lrate: 0.01; error: 77.674\n",
      "epoch: 17; lrate: 0.01; error: 77.661\n",
      "epoch: 18; lrate: 0.01; error: 77.65\n",
      "epoch: 19; lrate: 0.01; error: 77.64\n",
      "epoch: 20; lrate: 0.01; error: 77.631\n",
      "epoch: 21; lrate: 0.01; error: 77.623\n",
      "epoch: 22; lrate: 0.01; error: 77.616\n",
      "epoch: 23; lrate: 0.01; error: 77.61\n",
      "epoch: 24; lrate: 0.01; error: 77.604\n",
      "epoch: 25; lrate: 0.01; error: 77.598\n",
      "epoch: 26; lrate: 0.01; error: 77.593\n",
      "epoch: 27; lrate: 0.01; error: 77.588\n",
      "epoch: 28; lrate: 0.01; error: 77.583\n",
      "epoch: 29; lrate: 0.01; error: 77.579\n",
      "epoch: 30; lrate: 0.01; error: 77.575\n",
      "epoch: 31; lrate: 0.01; error: 77.571\n",
      "epoch: 32; lrate: 0.01; error: 77.567\n",
      "epoch: 33; lrate: 0.01; error: 77.563\n",
      "epoch: 34; lrate: 0.01; error: 77.56\n",
      "epoch: 35; lrate: 0.01; error: 77.556\n",
      "epoch: 36; lrate: 0.01; error: 77.553\n",
      "epoch: 37; lrate: 0.01; error: 77.55\n",
      "epoch: 38; lrate: 0.01; error: 77.546\n",
      "epoch: 39; lrate: 0.01; error: 77.543\n",
      "epoch: 40; lrate: 0.01; error: 77.54\n",
      "epoch: 41; lrate: 0.01; error: 77.537\n",
      "epoch: 42; lrate: 0.01; error: 77.535\n",
      "epoch: 43; lrate: 0.01; error: 77.532\n",
      "epoch: 44; lrate: 0.01; error: 77.529\n",
      "epoch: 45; lrate: 0.01; error: 77.526\n",
      "epoch: 46; lrate: 0.01; error: 77.524\n",
      "epoch: 47; lrate: 0.01; error: 77.521\n",
      "epoch: 48; lrate: 0.01; error: 77.519\n",
      "epoch: 49; lrate: 0.01; error: 77.516\n",
      "Scores: [0.1261879083508795, 0.12273886947920902, 0.11771848597609992, 0.12210657414311024, 0.12554877577808832]\n",
      "Mean RMSE: 0.123\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'wine.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.01\n",
    "n_epoch = 50\n",
    "scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5866f9b-802c-4db6-b705-2fc632021d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
